---
title: "Lab 06: Taming data"
description: |
  You can use this template for Lab 06. However, you will need to add the prose descriptions, add code comments, edit the data dictionary, and complete the self-assessment.
author: "Sicheng Wang"
bibliography: ["../bibliography.bib", "../packages.bib"]
---

```{r}
#| label: setup
#| message: false

library(dplyr)        # Inspecting and sub-setting data
library(knitr)        # Creating a table
library(readtext)     # Reading text content
library(readr)        # Reading and writing data
library(qtalrkit)     # Creating data dictionary
library(fs)           # Allowing assigning or getting a path to a directory
```

```{r}
#| label: acquire-data
#| message: false
#| echo: false
#| eval: false

# Assigning the link with data to file_url
file_url <- "https://github.com/francojc/activ-es/raw/master/activ-es-v.02/corpus/plain.zip"

# Assigning the directory path to dir_location
dir_location <- "../data/original/actives"

# Downloading the data from the link in file_url, decompressing the data to store it in the path mentioned in dir_location and the user need to confirme that they have permission to use the data
get_compressed_data(
  url = file_url,
  target_dir = dir_location,
  confirmed = TRUE
  )
```

## Data

<!--

- Overview of the data source and the purpose of this script

-->

From the corpus README, the chosen corpus contain the film dialogue from Argentine, Mexican and Spanish productions. The corpus contains the plain text, annotated text, running text with EAGLES tagset and wordlist file which seems can be used to compare Spanish from Argentina, Mexico, and Spain.

```{r}
#| label: dir-tree
#| echo: false

# Create a tree of the decompressed data structure
dir_tree(path = "../data/original/actives", recurse = 3) # only show the first three levels
```

### Description

<!--

- the name and/ or source of the data
- the nature of the data
- the acquisition strategy that was used
- the format of the data

-->

```{r}
#| label: tbl-data-origin-file
#| tbl-cap: "Data origin: Actives corpus"
#| tbl-colwidths: [30, 70]
#| message: false

# Read the actives_do.csv file into a table format
read_csv("../data/original/actives_do.csv") |>
  kable() # Create a table
```

*    This corpus is named as `ACTIV-ES: a comparable Spanish corpus comprised of film dialogue from Argentine, Mexican and Spanish productions (v.02)` from [ACTIV-ES](https://github.com/francojc/activ-es) which viewed as category data.

*    By programmatic download the data through R, found that the data contains running text files (.run), Part of Speech tagged files (.pos), and EAGLES tagged files (.eagles).

### Structure

<!--

- the relevant directories and data files
- the metadata and/ or variables to be organized
- the relationships between the data elements
- the idealized format for the curated dataset in a tabular format

-->

*       In `activ-es-v.02/corpus/`, it contains plain text, annotated files and EAGLES tagged files. The title shows the language code, country, year, title, type, genre and IMDb ID. Other variables like word, observed relative frequency and observed relative dispersion. The language code shows the spanish is from Argentina, Mexico, or Spain. The country shows where the texts in publishes come from. The year is when the publishes show up. The title is the name of publishes. The type is what kind of publishes they are. The genre shows the category of the publishes. IMDb ID is the number of the publishes' title. Word is a specific word, observed relative frequency is word occurrence per 100,000 and observed relative dispersion is occurrence of a word per 10 documents.
*    The aimed tabular format would contains 8 coloumns:  
language code, year, title, genre, IMDb ID, word, observed relative frequency and observed relative dispersion. I exclude country and type for the language code would reveal the country and type is movie. However if considering combining with other data, these two variables should be included.

## Curate

<!-- Overview of the data curation process -->

### Read

<!-- Description ... -->

```{r}
#| label: read-data-actives
#| message: false

# Create a vector doc_vars which contains variables `lang`, `country`, `year`, `title`, `type`, `genre` and `imdbid`
doc_vars <-
  c("lang", "country", "year", "title", "type", "genre", "imdbid")

# Assign the resulting data to actives_tbl
actives_tbl <-
  # read text in files
  readtext(
    file = "../data/original/actives/*.run", # read every file under `../data/original/actives/` whom match the `.run` pattern
    docvarsfrom = "filenames", # extract document variables from filenames
    docvarnames = doc_vars, # the names of the document variables is set in doc_vars
    verbosity = 0 # not show the messages
  ) |>
  as_tibble() # read the data into a tibble format

# preview
actives_tbl
```

### Tidy

<!-- Description ... -->

```{r}
#| label: tidy-data-actives

# add column information 
actives_tbl <-
  actives_tbl |>
  mutate(
    doc_id = row_number() # add a column named `doc_id` containing the row numbers for each document
  )

# Preview
actives_tbl
```

### Write

<!-- Description ... -->

```{r}
#| label: write-data-actives

# create a csv file
write_csv(
  x = actives_tbl, # make the actives_tbl to be a csv file
  file = "../data/derived/actives_curated.csv" # create the csv file under path
)
```

## Documentation

<!-- Overview of the purpose and structure of the documentation -->

### Data dictionary

<!-- Description ... -->

```{r}
#| label: create-data-dictionary
#| message: false

# create a data dictionary
create_data_dictionary(
  data = actives_tbl, # to contain information in actives_tbl
  file_path = "../data/derived/actives_curated_dd.csv" # create the data dictionary under this path
)
```

<!--

Note:

You will need to open and edit the `actives_curated_dd.csv` file to add the descriptions for each variable.

-->


```{r}
#| label: tbl-data-dictionary-show
#| tbl-cap: "Data dictionary: Actives corpus"
#| message: false

# read the csv file actives_curated_dd.csv
read_csv("../data/derived/actives_curated_dd.csv") |>
  kable() # read the csv file into the table format
```


### Project structure

<!-- Description ... -->

```{r}
#| label: show-directory-structure
#| echo: false

# Create a tree of the project structure
dir_tree("../", recurse = 2) # only show the first two levels
```

## Self-assessment

<!-- Complete the self-assessment -->



<!-- Review the .gitignore file to make sure that the data and datasets are not tracked by Git -->

<!-- Commit and push your repo -->
